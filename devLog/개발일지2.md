# 2주차

## 11월 12일
크롤링 과정이 총 3단계로 들어가야 한다. 셀레니움을 안써봐서 오래걸릴까봐 걱정했는데 다행히 많이 어렵지는 않았다.

셀레니움은 크롬드라이브를 깔고 설치된 크롬드라이브의 절대경로랑 연결시켜준 다음

크롬 사이트를 내 마음대로 제어해서 필요한 데이터들을 가져오면 된다!!

한 600개 정도되는 사이트를 열여서 데이터를 가져왔다. mongoDB에 저장되어있는거 보니까 뭔가 되게 뿌뜻했다..

자격증 정보를 내가 다 접수한 느낌!!!

<br>

## 11월 15일
API 목록을 정리해봤다.

그런데 첫번째 페이지에서 값을 받아서 두번째 페이지로 전달한다음 그 값에 해당하는 DB를 두번째 페이지에 뿌려줘야하는 과정에서 완전 멘붕이 와서

API 목록은 그냥 내 감각대로 필요한 것들만 생각했다,,, 

페이지간 데이터 전달이 매우 어려울 것으로 예상한다!

<br>


## 11월 16일
html 파일을 생성해서 첫번째 화면을 만들었다. 

마음같아선 UI를 엄청 예쁘게 만들고 싶은데 시간적 제약이 있기 때문에 최대한 심플하게 UI를 구성했었다.

그래서 별거 안들어가는데도 오래걸렸다,,,,

condepen에서 디자인들 보고 가져온다음에 하나씩 뜯어가면서 필요없는거 지우고 내가 필요한대로 수정하는 방식으로 코딩했다.

처음부터 다 내가 짜보려고 했는데 갈길이 멀어서 이렇게 했다,,,


<br>

## 11월 17일
페이지 이동하는 코드를 짜면 html에서는 되는데 서버를 실행시킨다음에 로컬주소로 들어가면 not found가 뜬다..

그래서 ajax로 통신하는 방법으로 페이지 로딩을 해야 할 것 같은데 감이 안잡힌다.

왜 not found가 뜨는 것일까,,,,왜?!?1?!?!??!?!?!?!


<br>

## 11월 18일
튜터님의 도움을 받아 엄청난 것들을 해결했다.

우선 어제 못했던 페이지 이동은 에러는 페이지 별로 app.py에다가 라우터를 만들어줘야 한다고 했다.

내가 아무리 두번쨰 html의 경로를 적어도 서버에서는 그걸 못 캐치하기때문에 라우터에 선언? 을 해줘야 한다!!

그렇게 했더니 해결됐다,, 그리고 걱정하던 페이지간 데이터 전달도 도와주셨다!!!

11월 18일의 TIL에다가 그 내용은 정리해 놨다ㅎㅎ

전달 받은 값으로 DB에 있는 값 받아와서 검색한 내용에 해당하는 결과를 뿌려주는 것 까지 했다.

우선 기능구현을 못할까봐 프론트는 약간 제쳐두고 백엔드부터 하는데 살짝 맘이 놓였다. 

이번주에 프로젝트에 시간을 많이 써야 겠다!




